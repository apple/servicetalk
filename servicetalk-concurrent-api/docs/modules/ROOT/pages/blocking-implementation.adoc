// Configure {source-root} values based on how this document is rendered: on GitHub or not
ifdef::env-github[]
:source-root:
endif::[]
ifndef::env-github[]
ifndef::source-root[:source-root: https://github.com/apple/servicetalk/blob/{page-origin-refname}]
endif::[]

= Blocking safe by default (Implementation Details)

As described xref:{page-version}@servicetalk-concurrent-api::blocking-safe-by-default.adoc[here], ServiceTalk by default
allows users to write blocking code when interacting with ServiceTalk. This document describes the details of the
implementation and is addressed to audiences who intend to know the internals of how this is achieved.

NOTE: It is not required to read this document if you just want to use ServiceTalk.

== Asynchronous Sources

Everything inside ServiceTalk is somehow connected to one of the three asynchronous sources, viz., `Publisher`, `Single`
and `Completable`. Since these sources are the building blocks for program control flow if they provide safety
guarantees for blocking code execution these guarantees apply outside the scope of preventing blocking code from
executing on event loop thread. This approach is designed to make the task of ensuring we don't block the event loop
threads less error-prone, and also allows for certain optimizations around thread context propagation and re-use.

== Threads and asynchronous sources

An asynchronous source has two important decisions to make about thread usage:

1. Which thread or executor will be used to do the actual work related to a source. eg: for an HTTP client, the work is to send an HTTP
request and read the HTTP response.
2. Which thread or executor will be used to interact with the `Subscriber` corresponding to its `Subscription`s.

In sometimes a single specific thread will be used but in most cases a thread from an `Executor` pool will be used.

Part 1. above is not governed by the
link:https://github.com/reactive-streams/reactive-streams-jvm/blob/v1.0.3/README.md#specification[ReactiveStreams specification]
and hence sources are free to use any thread. ServiceTalk typically will use Netty's `EventLoop` to do the actual work.
Part 2. defines all the interactions using the ReactiveStreams specifications, i.e. all methods in `Publisher`,
`Subscriber` and `Subscription`.

ServiceTalk concurrency APIs defines which thread will be used by any asynchronous source for Part 2.

== Task Offloading

ServiceTalk uses Netty for network I/O and the Netty implementation uses a fixed number of I/O threads for executing
network operations. To maximize throughput and minimize latency it is important to ensure that at least one I/O thread
is always ready to respond immediately to network activity. One approach to ensure I/O thread availability is to
carefully limit the scope of work done by I/O threads and, when practical, perform any other necessary work on some
other non-precious thread. Moving work from I/O threads to other threads is called “offloading” and is a core technique
used by ServiceTalk.

ServiceTalk will, by default, execute most application code on an offloaded “safe” thread. If the application developer
knows that their code cannot block and always executes quickly in near constant time they can request that ServiceTalk
not offload their code. This will improve application performance by reducing latency and overhead. Requests to not
offload will be honored by ServiceTalk if all the other components in the same execution path have also opted out of
offloading. As a last resort, work tasks may also be queued to be performed as threads are available.

ServiceTalk is designed to be full asynchronous except where the API provides explicit blocking behaviour as a
convenience. Offloading is the execution of program logic code using a thread (or equivalent) other than the application
thread which originally initiated the operation. Offloading is used for two purposes within ServiceTalk; firstly for the
execution needed for the handling of asynchronous events, aka Signals, and secondly when handling asynchronous events,
protecting scarce resources from being monopolized by blocking, untrusted or expensive application code. Asynchronous
execution requires offloading—the initiating application thread is not available. Protective offloading is a practical
consideration, but just as necessary for reliable and predictable operation.

Task based offloading uses an `Executor` in the traditional way to run the offloaded tasks. Often the Executor has a
pool of threads, possibly unbounded, and tasks are run using whatever thread is available. In particular, different
threads may be used for each task executed and code running in tasks cannot depend upon a consistent thread being used
for invoking program logic. This approach is generally the most scalable because it makes the best utilization of
threads.

== Offloading and asynchronous sources

ServiceTalk allows control of the thread that will be used for the signals of an asynchronous source. A safe
used based upon the decision logic described earlier but for time consuming tasks an `Executor` may be specified.
The `subscribeOn()` and `publishOn()` operators will offload execution from the default thread to a thread from the
provided `Executor`. The below diagram illustrates the interaction between an asynchronous source, its `Subscriber`,
its operators, and the `Executor`.

image::offloading.svg[Offloading]

During `subscribe()` the execution will offload at the `subscribeOn()` operator and transition execution from the
application thread to an `Exeuctor` thread. The application thread will be able to continue while the subscribe
operation asynchronously continues on an `Executor` thread.

When a result is available at the source it will begin
publication using the receiving event loop thread but will offload at the `publishOn()` operator and transition
execution from the event loop thread to an `Executor` thread. Once the publish signal is offloaded the event loop thread
will be available again for executing other I/O tasks while the response is asynchronously processed on the `Executor`
thread.

Taking the same example from xref:{page-version}@servicetalk-concurrent-api::blocking-safe-by-default.adoc[here]

[source, java]
----
 client.request() # <1>
       .map(resp -> {
            return resp.toString(); # <2>
       })
       .publishOn(executor) # <3>
       .flatMap(stringResp -> { # <4>
            return client2.request(stringResp);
       })
       .filter(stringResp -> {
            stringResp.equals("Hello World");  # <5>
       });
----
<1> A hypothetical client which provides a `request()` method that returns a `Single<Response>`.
<2> Converting the response to a `String`.
<3> Offload execution to the provided `Executor`
<4> Call another `client2` that provides a new `Single` which is returned from `flatMap`.
<5> Only allow "Hello World" messages to be emitted.

In the above example the operators `map` and `filter` do not need to offload since they do not do
any asynchronous work. However, `flatmap` should be offloaded since it asynchronously executes another request. Adding
a `publishOn(Executor)` operator before `flatmap` ensures that the event loop thread which delivered the original
response is not blocked.
